{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3Ke1wsAD0af",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwpRcblyDqoK",
        "colab_type": "code",
        "outputId": "007988ce-0ee3-45c2-da66-b56d19c95832",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiueRzjEIYL6",
        "colab_type": "code",
        "outputId": "3c31d203-3399-4d10-95f9-8e0f30a4dce6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "# Cloning BERT git repo\n",
        "!git clone https://github.com/google-research/bert.git\n",
        "!mv bert bert-master"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert'...\n",
            "remote: Enumerating objects: 340, done.\u001b[K\n",
            "remote: Total 340 (delta 0), reused 0 (delta 0), pack-reused 340\u001b[K\n",
            "Receiving objects: 100% (340/340), 300.28 KiB | 20.02 MiB/s, done.\n",
            "Resolving deltas: 100% (185/185), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wejnTnwQE9OU",
        "colab_type": "code",
        "outputId": "b511e38b-ff80-4a94-ed54-095b49bbe4ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "# Downloading BERT-Base, Cased Model\n",
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip -O cased.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-24 21:02:28--  https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.15.80, 2607:f8b0:4004:c09::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.15.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 404261442 (386M) [application/zip]\n",
            "Saving to: ‘cased.zip’\n",
            "\n",
            "cased.zip           100%[===================>] 385.53M   107MB/s    in 3.6s    \n",
            "\n",
            "2020-03-24 21:02:32 (107 MB/s) - ‘cased.zip’ saved [404261442/404261442]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n95Usiu-GCap",
        "colab_type": "code",
        "outputId": "c2566e8d-994a-4971-e829-f71e0cb26395",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "# Unzipping the downloaded folder and placing it into root/model\n",
        "!mkdir model/\n",
        "!unzip cased.zip -d model/\n",
        "!rm cased.zip\n",
        "!cd model/cased_L-12_H-768_A-12 && mv * .. && cd .. && rm -r cased_L-12_H-768_A-12\n",
        "\n",
        "# Moving the model folder into root/bert-master\n",
        "!mv model bert-master"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cased.zip\n",
            "   creating: model/cased_L-12_H-768_A-12/\n",
            "  inflating: model/cased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: model/cased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: model/cased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: model/cased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: model/cased_L-12_H-768_A-12/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1dCxNTrH3Gw",
        "colab_type": "code",
        "outputId": "25db969e-e89f-4aa0-a47e-7f250f78a19c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "## MAKE SURE YOUR CSV FILES ARE IN THE ROOT THEN RUN THIS CELL!!!!!!!!!\n",
        "!mkdir dataset\n",
        "!mv data.csv dataset/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘dataset’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ILA5G6WGRks",
        "colab_type": "code",
        "outputId": "482308e6-1a9a-4eaa-e1d3-e70bf6e2148a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "# # If needed:\n",
        "# !pip3 install pandas, sklearn\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Read data from csv file\n",
        "df_dataset = pd.read_csv('dataset/data.csv')\n",
        "\n",
        "# Creating the unique identifiers for the dataset\n",
        "ids = []\n",
        "for i in range(len(df_dataset)):\n",
        "  ids.append(i)\n",
        "pd_ids = pd.DataFrame(ids)\n",
        "df_dataset.insert(0, \"id\", pd_ids)\n",
        "# Converting sentiments from \"positive\" and \"negative\" to 1 and 0\n",
        "df_dataset['sentiment'] = df_dataset['sentiment'].map({'positive': 1, 'negative': 0})\n",
        "\n",
        "#########################\n",
        "############# \n",
        "# SHOULD REMOVE STOP WORDS AND DO STEMMING HERE\n",
        "#############\n",
        "#########################\n",
        "\n",
        "# Split into test and train set\n",
        "df_train, df_test = train_test_split(df_dataset, test_size=0.2, shuffle=True)\n",
        "\n",
        "# # Create new dataframes in the format required by BERT for train, dev data\n",
        "df_bert = pd.DataFrame({'guid': df_train['id'],\n",
        "                        'label': df_train['sentiment'],\n",
        "                        'alpha': ['a'] * df_train.shape[0],\n",
        "                        'text': df_train['review']})\n",
        "\n",
        "# Split into test, dev\n",
        "df_bert_train, df_bert_dev = train_test_split(df_bert, test_size=0.01)\n",
        "\n",
        "# Create new dataframe for test data\n",
        "df_bert_test = pd.DataFrame({'guid': df_test['id'],\n",
        "                             'text': df_test['review']})\n",
        "\n",
        "# Output tsv file, no header for train and dev\n",
        "!mkdir bert-master/dataset\n",
        "df_bert_train.to_csv('bert-master/dataset/train.tsv', sep='\\t', index=False, header=False)\n",
        "df_bert_dev.to_csv('bert-master/dataset/dev.tsv', sep='\\t', index=False, header=False)\n",
        "df_bert_test.to_csv('bert-master/dataset/test.tsv', sep='\\t', index=False, header=True)\n",
        "\n",
        "print(df_bert_train.head())\n",
        "print(\"-\" * 100)\n",
        "print(df_bert_test.head())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘bert-master/dataset’: File exists\n",
            "        guid  label alpha                                               text\n",
            "37771  37771      1     a  I absolutely loved movie. I bought soon I coul...\n",
            "32679  32679      0     a  A resurrected wrapped monster goes murdering b...\n",
            "18497  18497      0     a  What horrible writing acting. No personality. ...\n",
            "33461  33461      0     a  Now I love Bela Lugosi,don't get wrong,he one ...\n",
            "944      944      1     a  For Has-Beens Never Was's curious, film you......\n",
            "----------------------------------------------------------------------------------------------------\n",
            "        guid                                               text\n",
            "34369  34369  It's close ten years since I've seen either la...\n",
            "14024  14024  <br /><br />I seen movie many times. At least ...\n",
            "43021  43021  I Sociologist/Anthropologist specializing fiel...\n",
            "44751  44751  I amazed improvements made animated film. If s...\n",
            "46198  46198  Plankton, Creatures Abyss I'm positive commonl...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRTHJNB8P2_i",
        "colab_type": "code",
        "outputId": "aa76c615-2187-4aa0-fb8b-e33bfec8daed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Mar 24 21:28:13 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8     7W /  75W |      0MiB /  7611MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38P0D8pSavt0",
        "colab_type": "code",
        "outputId": "54268daf-da7e-4dfa-8d23-f064cc98be0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!cd bert-master && CUDA_VISIBLE_DEVICES=0 python3 run_classifier.py --task_name=cola --do_train=true --do_eval=true --data_dir=./dataset --vocab_file=./model/vocab.txt --bert_config_file=./model/bert_config.json --init_checkpoint=./model/bert_model.ckpt --max_seq_length=128 --train_batch_size=2 --learning_rate=2e-5 --num_train_epochs=3.0 --output_dir=./bert_output/ --do_lower_case=False --save_checkpoints_steps 1000"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0319 18:22:28.860811 139641452205952 deprecation.py:323] From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:training_loop marked as finished\n",
            "I0319 18:22:33.524011 139641452205952 error_handling.py:101] training_loop marked as finished\n",
            "Traceback (most recent call last):\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/ops.py\", line 5628, in init_scope\n",
            "    yield\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/variables.py\", line 1818, in _init_from_args\n",
            "    initial_value(), name=\"initial_value\", dtype=dtype)\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/variable_scope.py\", line 905, in <lambda>\n",
            "    partition_info=partition_info)\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/init_ops.py\", line 114, in __call__\n",
            "    return array_ops.zeros(shape, dtype)\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/array_ops.py\", line 2344, in zeros\n",
            "    tensor_shape.TensorShape(shape))\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/constant_op.py\", line 321, in _tensor_shape_tensor_conversion_function\n",
            "    return constant(s_list, dtype=dtype, name=name)\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/constant_op.py\", line 227, in constant\n",
            "    allow_broadcast=True)\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/constant_op.py\", line 271, in _constant_impl\n",
            "    name=name).outputs[0]\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/util/deprecation.py\", line 480, in new_func\n",
            "    named_args = tf_inspect.getcallargs(func, *args, **kwargs)\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/util/tf_inspect.py\", line 278, in getcallargs\n",
            "    argspec = getfullargspec(func)\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/util/tf_inspect.py\", line 257, in getfullargspec\n",
            "    return _getfullargspec(target)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1126, in getfullargspec\n",
            "    sigcls=Signature)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"run_classifier.py\", line 981, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"run_classifier.py\", line 880, in main\n",
            "    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 3030, in train\n",
            "    saving_listeners=saving_listeners)\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n",
            "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n",
            "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1191, in _train_model_default\n",
            "    features, labels, ModeKeys.TRAIN, self.config)\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 2857, in _call_model_fn\n",
            "    config)\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1149, in _call_model_fn\n",
            "    model_fn_results = self._model_fn(features=features, **kwargs)\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 3126, in _model_fn\n",
            "    features, labels, is_export_mode=is_export_mode)\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 1663, in call_without_tpu\n",
            "    return self._call_model_fn(features, labels, is_export_mode=is_export_mode)\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 1994, in _call_model_fn\n",
            "    estimator_spec = self._model_fn(features=features, **kwargs)\n",
            "  File \"run_classifier.py\", line 675, in model_fn\n",
            "    total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
            "  File \"/content/bert-master/optimization.py\", line 77, in create_optimizer\n",
            "    zip(grads, tvars), global_step=global_step)\n",
            "  File \"/content/bert-master/optimization.py\", line 122, in apply_gradients\n",
            "    initializer=tf.zeros_initializer())\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/variable_scope.py\", line 1500, in get_variable\n",
            "    aggregation=aggregation)\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/variable_scope.py\", line 1243, in get_variable\n",
            "    aggregation=aggregation)\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/variable_scope.py\", line 567, in get_variable\n",
            "    aggregation=aggregation)\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/variable_scope.py\", line 519, in _true_getter\n",
            "    aggregation=aggregation)\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/variable_scope.py\", line 933, in _get_single_variable\n",
            "    aggregation=aggregation)\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/variables.py\", line 258, in __call__\n",
            "    return cls._variable_v1_call(*args, **kwargs)\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/variables.py\", line 219, in _variable_v1_call\n",
            "    shape=shape)\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/variables.py\", line 197, in <lambda>\n",
            "    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/variable_scope.py\", line 2519, in default_variable_creator\n",
            "    shape=shape)\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/variables.py\", line 262, in __call__\n",
            "    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/variables.py\", line 1688, in __init__\n",
            "    shape=shape)\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/variables.py\", line 1873, in _init_from_args\n",
            "    ops.add_to_collections(collections, self)\n",
            "  File \"/usr/lib/python3.6/contextlib.py\", line 99, in __exit__\n",
            "    self.gen.throw(type, value, traceback)\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/ops.py\", line 5628, in init_scope\n",
            "    yield\n",
            "  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/ops.py\", line 6352, in __exit__\n",
            "    def __exit__(self, type_arg, value_arg, traceback_arg):\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoRfD8bzgCOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}